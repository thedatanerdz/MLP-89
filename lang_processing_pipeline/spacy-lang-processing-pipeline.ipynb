{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h2 align=\"center\">Spacy Language Processing Pipelines Tutorial</h2>","metadata":{}},{"cell_type":"markdown","source":"<h3>Blank nlp pipeline</h3>","metadata":{}},{"cell_type":"code","source":"import spacy\n\nnlp = spacy.blank(\"en\")\n\ndoc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n\nfor token in doc:\n    print(token)","metadata":{},"execution_count":90,"outputs":[{"name":"stdout","output_type":"stream","text":"Captain\n\namerica\n\nate\n\n100\n\n$\n\nof\n\nsamosa\n\n.\n\nThen\n\nhe\n\nsaid\n\nI\n\ncan\n\ndo\n\nthis\n\nall\n\nday\n\n.\n"}]},{"cell_type":"markdown","source":"We get above error because we have a blank pipeline as shown below. Pipeline is something that starts with a Tokenizer component in a dotted rectange below. You can see there is nothing there hence the blank pipeline","metadata":{}},{"cell_type":"markdown","source":"<img height=300 width=400 src=\"spacy_blank_pipeline.jpg\" />","metadata":{}},{"cell_type":"code","source":"nlp.pipe_names","metadata":{"scrolled":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{}}]},{"cell_type":"markdown","source":"nlp.pipe_names is empty array indicating no components in the pipeline. Pipeline is something that starts with a tokenizer ","metadata":{}},{"cell_type":"markdown","source":"More general diagram for nlp pipeline may look something like below","metadata":{}},{"cell_type":"markdown","source":"<img height=300 width=400 src=\"spacy_loaded_pipeline.jpg\" />","metadata":{}},{"cell_type":"markdown","source":"<h3>Download trained pipeline</h3>","metadata":{}},{"cell_type":"markdown","source":"To download trained pipeline use a command such as,\n\npython -m spacy download en_core_web_sm\n\nThis downloads the small (sm) pipeline for english language\n\nFurther instructions on : https://spacy.io/usage/models#quickstart","metadata":{}},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\nnlp.pipe_names","metadata":{},"execution_count":85,"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":["['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"]},"metadata":{}}]},{"cell_type":"code","source":"nlp.pipeline","metadata":{},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":["[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x1b5ddd5f5e0>),\n"," ('tagger', <spacy.pipeline.tagger.Tagger at 0x1b5ddd5f280>),\n"," ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x1b5ddd66a50>),\n"," ('attribute_ruler',\n","  <spacy.pipeline.attributeruler.AttributeRuler at 0x1b5d92391c0>),\n"," ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x1b5d922ae00>),\n"," ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x1b5d996e660>)]"]},"metadata":{}}]},{"cell_type":"markdown","source":"sm in en_core_web_sm means small. There are other models available as well such as medium, large etc. Check this: https://spacy.io/usage/models#quickstart","metadata":{}},{"cell_type":"code","source":"doc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n\nfor token in doc:\n    print(token, \" | \", spacy.explain(token.pos_), \" | \", token.lemma_)","metadata":{"scrolled":true},"execution_count":87,"outputs":[{"name":"stdout","output_type":"stream","text":"Captain  |  proper noun  |  Captain\n\namerica  |  proper noun  |  america\n\nate  |  verb  |  eat\n\n100  |  numeral  |  100\n\n$  |  numeral  |  $\n\nof  |  adposition  |  of\n\nsamosa  |  proper noun  |  samosa\n\n.  |  punctuation  |  .\n\nThen  |  adverb  |  then\n\nhe  |  pronoun  |  he\n\nsaid  |  verb  |  say\n\nI  |  pronoun  |  I\n\ncan  |  auxiliary  |  can\n\ndo  |  verb  |  do\n\nthis  |  pronoun  |  this\n\nall  |  determiner  |  all\n\nday  |  noun  |  day\n\n.  |  punctuation  |  .\n"}]},{"cell_type":"markdown","source":"**Run same code above with a blank pipeline and check what output you see?**","metadata":{}},{"cell_type":"markdown","source":"<h3>Named Entity Recognition</h3>","metadata":{}},{"cell_type":"code","source":"doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\nfor ent in doc.ents:\n    print(ent.text, ent.label_)","metadata":{"scrolled":true},"execution_count":34,"outputs":[{"name":"stdout","output_type":"stream","text":"Tesla Inc ORG\n\n$45 billion MONEY\n"}]},{"cell_type":"code","source":"from spacy import displacy\n\ndisplacy.render(doc, style=\"ent\")","metadata":{},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Tesla Inc\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," va racheter \n","<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    Twitter\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n","</mark>\n"," pour $45 milliards de dollars</div></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}]},{"cell_type":"markdown","source":"<h3>Trained processing pipeline in French</h3>","metadata":{}},{"cell_type":"code","source":"nlp = spacy.load(\"fr_core_news_sm\")","metadata":{},"execution_count":26,"outputs":[{"ename":"OSError","evalue":"[E050] Can't find model 'fr_core_news_sm'. It doesn't seem to be a Python package or a valid path to a data directory.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[1;32m<ipython-input-26-8f4c0b2c70cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fr_core_news_sm\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \"\"\"\n\u001b[1;32m---> 51\u001b[1;33m     return util.load_model(\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     )\n","\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[index]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'fr_core_news_sm'. It doesn't seem to be a Python package or a valid path to a data directory."]}]},{"cell_type":"markdown","source":"You need to install the processing pipeline for french language using this command,\n\npython -m spacy download fr_core_news_sm","metadata":{}},{"cell_type":"code","source":"nlp = spacy.load(\"fr_core_news_sm\")","metadata":{},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"doc = nlp(\"Tesla Inc va racheter Twitter pour $45 milliards de dollars\")\nfor ent in doc.ents:\n    print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))","metadata":{},"execution_count":42,"outputs":[{"name":"stdout","output_type":"stream","text":"Tesla Inc  |  ORG  |  Companies, agencies, institutions, etc.\n\nTwitter  |  MISC  |  Miscellaneous entities, e.g. events, nationalities, products or works of art\n"}]},{"cell_type":"code","source":"for token in doc:\n    print(token, \" | \", token.pos_, \" | \", token.lemma_)","metadata":{},"execution_count":39,"outputs":[{"name":"stdout","output_type":"stream","text":"Tesla  |  X  |  Tesla\n\nInc  |  X  |  Inc\n\nva  |  VERB  |  aller\n\nracheter  |  VERB  |  racheter\n\nTwitter  |  VERB  |  twitter\n\npour  |  ADP  |  pour\n\n$  |  NOUN  |  dollar\n\n45  |  NUM  |  45\n\nmilliards  |  NOUN  |  milliard\n\nde  |  ADP  |  de\n\ndollars  |  NOUN  |  dollar\n"}]},{"cell_type":"markdown","source":"<h3>Adding a component to a blank pipeline</h3>","metadata":{}},{"cell_type":"code","source":"source_nlp = spacy.load(\"en_core_web_sm\")\n\nnlp = spacy.blank(\"en\")\nnlp.add_pipe(\"ner\", source=source_nlp)\nnlp.pipe_names","metadata":{},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":["['ner']"]},"metadata":{}}]},{"cell_type":"code","source":"doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\nfor ent in doc.ents:\n    print(ent.text, ent.label_)","metadata":{},"execution_count":81,"outputs":[{"name":"stdout","output_type":"stream","text":"Tesla Inc ORG\n\n$45 billion MONEY\n"}]},{"cell_type":"markdown","source":"In below image you can see sentecizer component in the pipeline","metadata":{}},{"cell_type":"markdown","source":"<img height=300 width=400 src=\"sentecizer.jpg\" />","metadata":{}},{"cell_type":"markdown","source":"<h3>Further reading</h3>","metadata":{}},{"cell_type":"markdown","source":"https://spacy.io/usage/processing-pipelines#pipelines","metadata":{}}]}