{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h2 align=\"center\">Spacy Language Processing Pipelines Tutorial</h2>","metadata":{}},{"cell_type":"markdown","source":"<h3>Blank nlp pipeline</h3>","metadata":{}},{"cell_type":"code","source":"import spacy\n\nnlp = spacy.blank(\"en\")\n\ndoc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n\nfor token in doc:\n    print(token)","metadata":{"execution":{"iopub.status.busy":"2023-08-15T09:49:56.981876Z","iopub.execute_input":"2023-08-15T09:49:56.982281Z","iopub.status.idle":"2023-08-15T09:50:12.152195Z","shell.execute_reply.started":"2023-08-15T09:49:56.982249Z","shell.execute_reply":"2023-08-15T09:50:12.150751Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"Captain\namerica\nate\n100\n$\nof\nsamosa\n.\nThen\nhe\nsaid\nI\ncan\ndo\nthis\nall\nday\n.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We get above error because we have a blank pipeline as shown below. Pipeline is something that starts with a Tokenizer component in a dotted rectange below. You can see there is nothing there hence the blank pipeline","metadata":{}},{"cell_type":"markdown","source":"<img height=300 width=400 src=\"/kaggle/input/lang-pipeline/spacy_blank_pipeline.jpg\" />","metadata":{}},{"cell_type":"code","source":"nlp.pipe_names","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-08-15T09:50:12.154582Z","iopub.execute_input":"2023-08-15T09:50:12.155521Z","iopub.status.idle":"2023-08-15T09:50:12.165020Z","shell.execute_reply.started":"2023-08-15T09:50:12.155473Z","shell.execute_reply":"2023-08-15T09:50:12.163545Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"markdown","source":"nlp.pipe_names is empty array indicating no components in the pipeline. Pipeline is something that starts with a tokenizer ","metadata":{}},{"cell_type":"markdown","source":"More general diagram for nlp pipeline may look something like below","metadata":{}},{"cell_type":"markdown","source":"<img height=300 width=400 src=\"/kaggle/input/lang-pipeline/spacy_loaded_pipeline.jpg\" />","metadata":{}},{"cell_type":"markdown","source":"<h3>Download trained pipeline</h3>","metadata":{}},{"cell_type":"markdown","source":"To download trained pipeline use a command such as,\n\npython -m spacy download en_core_web_sm\n\nThis downloads the small (sm) pipeline for english language\n\nFurther instructions on : https://spacy.io/usage/models#quickstart","metadata":{}},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")\nnlp.pipe_names","metadata":{"execution":{"iopub.status.busy":"2023-08-15T09:50:12.166745Z","iopub.execute_input":"2023-08-15T09:50:12.167419Z","iopub.status.idle":"2023-08-15T09:50:13.460139Z","shell.execute_reply.started":"2023-08-15T09:50:12.167178Z","shell.execute_reply":"2023-08-15T09:50:13.458765Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"},"metadata":{}}]},{"cell_type":"code","source":"nlp.pipeline","metadata":{"execution":{"iopub.status.busy":"2023-08-15T09:50:13.465185Z","iopub.execute_input":"2023-08-15T09:50:13.465590Z","iopub.status.idle":"2023-08-15T09:50:13.473955Z","shell.execute_reply.started":"2023-08-15T09:50:13.465554Z","shell.execute_reply":"2023-08-15T09:50:13.472592Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7f2d2d79b6a0>),\n ('tagger', <spacy.pipeline.tagger.Tagger at 0x7f2d2d79a080>),\n ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7f2daa901d90>),\n ('attribute_ruler',\n  <spacy.pipeline.attributeruler.AttributeRuler at 0x7f2d2d484600>),\n ('lemmatizer',\n  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7f2d2d481340>),\n ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7f2d2d896f10>)]"},"metadata":{}}]},{"cell_type":"markdown","source":"sm in en_core_web_sm means small. There are other models available as well such as medium, large etc. Check this: https://spacy.io/usage/models#quickstart","metadata":{}},{"cell_type":"code","source":"doc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n\nfor token in doc:\n    print(token, \" | \", spacy.explain(token.pos_), \" | \", token.lemma_)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-08-15T09:50:13.475570Z","iopub.execute_input":"2023-08-15T09:50:13.476528Z","iopub.status.idle":"2023-08-15T09:50:13.516096Z","shell.execute_reply.started":"2023-08-15T09:50:13.476480Z","shell.execute_reply":"2023-08-15T09:50:13.514905Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Captain  |  proper noun  |  Captain\namerica  |  proper noun  |  america\nate  |  verb  |  eat\n100  |  numeral  |  100\n$  |  numeral  |  $\nof  |  adposition  |  of\nsamosa  |  proper noun  |  samosa\n.  |  punctuation  |  .\nThen  |  adverb  |  then\nhe  |  pronoun  |  he\nsaid  |  verb  |  say\nI  |  pronoun  |  I\ncan  |  auxiliary  |  can\ndo  |  verb  |  do\nthis  |  pronoun  |  this\nall  |  determiner  |  all\nday  |  noun  |  day\n.  |  punctuation  |  .\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Run same code above with a blank pipeline and check what output you see?**","metadata":{}},{"cell_type":"markdown","source":"<h3>Named Entity Recognition</h3>","metadata":{}},{"cell_type":"code","source":"doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\nfor ent in doc.ents:\n    print(ent.text, ent.label_)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-08-15T09:50:13.517751Z","iopub.execute_input":"2023-08-15T09:50:13.518144Z","iopub.status.idle":"2023-08-15T09:50:13.537528Z","shell.execute_reply.started":"2023-08-15T09:50:13.518111Z","shell.execute_reply":"2023-08-15T09:50:13.536264Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Tesla Inc ORG\n$45 billion MONEY\n","output_type":"stream"}]},{"cell_type":"code","source":"from spacy import displacy\n\ndisplacy.render(doc, style=\"ent\")","metadata":{"execution":{"iopub.status.busy":"2023-08-15T09:50:13.538869Z","iopub.execute_input":"2023-08-15T09:50:13.539225Z","iopub.status.idle":"2023-08-15T09:50:13.549357Z","shell.execute_reply.started":"2023-08-15T09:50:13.539195Z","shell.execute_reply":"2023-08-15T09:50:13.548127Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Tesla Inc\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n</mark>\n is going to acquire twitter for \n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    $45 billion\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n</mark>\n</div></span>"},"metadata":{}}]},{"cell_type":"markdown","source":"<h3>Trained processing pipeline in French</h3>","metadata":{}},{"cell_type":"code","source":"!python -m spacy download fr_core_news_sm","metadata":{"execution":{"iopub.status.busy":"2023-08-15T09:52:06.329196Z","iopub.execute_input":"2023-08-15T09:52:06.329586Z","iopub.status.idle":"2023-08-15T09:52:30.657434Z","shell.execute_reply.started":"2023-08-15T09:52:06.329557Z","shell.execute_reply":"2023-08-15T09:52:30.656336Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\nCollecting fr-core-news-sm==3.6.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.6.0/fr_core_news_sm-3.6.0-py3-none-any.whl (16.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /opt/conda/lib/python3.10/site-packages (from fr-core-news-sm==3.6.0) (3.6.0)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.0.4)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.0.9)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.0.7)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.0.8)\nRequirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (8.1.10)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.4.6)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.0.8)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.9.0)\nRequirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.10.2)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (6.3.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (4.65.0)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.23.5)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.10.9)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (59.8.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.0.9)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (4.6.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2023.5.7)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.7.9)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.1.0)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (8.1.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.1.3)\nInstalling collected packages: fr-core-news-sm\nSuccessfully installed fr-core-news-sm-3.6.0\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('fr_core_news_sm')\n","output_type":"stream"}]},{"cell_type":"code","source":"nlp = spacy.load(\"fr_core_news_sm\")","metadata":{"execution":{"iopub.status.busy":"2023-08-15T09:53:08.277598Z","iopub.execute_input":"2023-08-15T09:53:08.278075Z","iopub.status.idle":"2023-08-15T09:53:16.895618Z","shell.execute_reply.started":"2023-08-15T09:53:08.278032Z","shell.execute_reply":"2023-08-15T09:53:16.894400Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"You need to install the processing pipeline for french language using this command,\n\npython -m spacy download fr_core_news_sm","metadata":{}},{"cell_type":"code","source":"nlp = spacy.load(\"fr_core_news_sm\")","metadata":{"execution":{"iopub.status.busy":"2023-08-15T09:53:21.365903Z","iopub.execute_input":"2023-08-15T09:53:21.366329Z","iopub.status.idle":"2023-08-15T09:53:23.518335Z","shell.execute_reply.started":"2023-08-15T09:53:21.366292Z","shell.execute_reply":"2023-08-15T09:53:23.517407Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"doc = nlp(\"Tesla Inc va racheter Twitter pour $45 milliards de dollars\")\nfor ent in doc.ents:\n    print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))","metadata":{"execution":{"iopub.status.busy":"2023-08-15T09:53:25.709414Z","iopub.execute_input":"2023-08-15T09:53:25.709879Z","iopub.status.idle":"2023-08-15T09:53:25.733549Z","shell.execute_reply.started":"2023-08-15T09:53:25.709843Z","shell.execute_reply":"2023-08-15T09:53:25.732243Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Tesla Inc  |  ORG  |  Companies, agencies, institutions, etc.\nTwitter  |  MISC  |  Miscellaneous entities, e.g. events, nationalities, products or works of art\n","output_type":"stream"}]},{"cell_type":"code","source":"for token in doc:\n    print(token, \" | \", token.pos_, \" | \", token.lemma_)","metadata":{"execution":{"iopub.status.busy":"2023-08-15T09:53:28.289282Z","iopub.execute_input":"2023-08-15T09:53:28.289656Z","iopub.status.idle":"2023-08-15T09:53:28.296709Z","shell.execute_reply.started":"2023-08-15T09:53:28.289627Z","shell.execute_reply":"2023-08-15T09:53:28.295466Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Tesla  |  PROPN  |  Tesla\nInc  |  PROPN  |  Inc\nva  |  VERB  |  aller\nracheter  |  VERB  |  racheter\nTwitter  |  VERB  |  twitter\npour  |  ADP  |  pour\n$  |  NOUN  |  dollar\n45  |  NUM  |  45\nmilliards  |  NOUN  |  milliard\nde  |  ADP  |  de\ndollars  |  NOUN  |  dollar\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<h3>Adding a component to a blank pipeline</h3>","metadata":{}},{"cell_type":"code","source":"source_nlp = spacy.load(\"en_core_web_sm\")\n\nnlp = spacy.blank(\"en\")\nnlp.add_pipe(\"ner\", source=source_nlp)\nnlp.pipe_names","metadata":{"execution":{"iopub.status.busy":"2023-08-15T09:53:30.671182Z","iopub.execute_input":"2023-08-15T09:53:30.671637Z","iopub.status.idle":"2023-08-15T09:53:32.286626Z","shell.execute_reply.started":"2023-08-15T09:53:30.671600Z","shell.execute_reply":"2023-08-15T09:53:32.285528Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"['ner']"},"metadata":{}}]},{"cell_type":"code","source":"doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\nfor ent in doc.ents:\n    print(ent.text, ent.label_)","metadata":{"execution":{"iopub.status.busy":"2023-08-15T09:53:34.872957Z","iopub.execute_input":"2023-08-15T09:53:34.873332Z","iopub.status.idle":"2023-08-15T09:53:34.884879Z","shell.execute_reply.started":"2023-08-15T09:53:34.873302Z","shell.execute_reply":"2023-08-15T09:53:34.883418Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Tesla Inc ORG\n$45 billion MONEY\n","output_type":"stream"}]},{"cell_type":"markdown","source":"In below image you can see sentecizer component in the pipeline","metadata":{}},{"cell_type":"markdown","source":"<img height=300 width=400 src=\"/kaggle/input/lang-pipeline/sentecizer.jpg\"/>","metadata":{}},{"cell_type":"markdown","source":"<h3>Further reading</h3>","metadata":{}},{"cell_type":"markdown","source":"https://spacy.io/usage/processing-pipelines#pipelines","metadata":{}}]}